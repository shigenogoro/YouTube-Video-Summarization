{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-click: clone repo into Colab runtime and install dependencies (idempotent)\n",
    "import os, subprocess, sys\n",
    "\n",
    "repo_dir = 'YouTube-Video-Summarization'\n",
    "if not os.path.exists(repo_dir):\n",
    "    print('Cloning repository...')\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/shigenogoro/YouTube-Video-Summarization.git'], check=False)\n",
    "else:\n",
    "    print('Repository already present:', repo_dir)\n",
    "\n",
    "# Change into repo directory\n",
    "os.chdir(repo_dir)\n",
    "print('Working directory:', os.getcwd())\n",
    "\n",
    "# Install requirements (quiet). If you prefer to edit this, remove --quiet.\n",
    "print('Installing python dependencies (this may take a minute)...')\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt', '--quiet'], check=False)\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'transformers', 'datasets', 'evaluate', 'accelerate'], check=False)\n",
    "print('Dependencies installation step finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure repository root is on sys.path by locating the `src/` marker directory\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(marker='src'):\n",
    "    p = Path('.').resolve()\n",
    "    for candidate in [p] + list(p.parents):\n",
    "        if (candidate / marker).exists():\n",
    "            return candidate\n",
    "    return p\n",
    "\n",
    "repo_root = find_repo_root('src')\n",
    "# If we cloned into a subfolder, prefer that location\n",
    "if (repo_root / '.git').exists():\n",
    "    print('Found repo root:', repo_root)\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "print('Repo root added to sys.path ->', repo_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef138b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Colab) and optionally set DATA_CFG['path']\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "    # Suggested default path on Drive - adjust as needed\n",
    "    default = '/content/drive/MyDrive/YouTube-Video-Summarization/data'\n",
    "    use_drive = input(f\"Use Google Drive dataset path? (leave blank to use suggested default) [default: {default}]: \")\n",
    "    if use_drive.strip() == '':\n",
    "        DATA_CFG['path'] = default\n",
    "    else:\n",
    "        DATA_CFG['path'] = use_drive.strip()\n",
    "    print('DATA_CFG[\"path\"] set to', DATA_CFG['path'])\n",
    "except Exception as e:\n",
    "    print('Not running in Colab or Drive mount failed:', e)\n",
    "    print('If you mounted Drive manually, set DATA_CFG[\"path\"] accordingly before dataset loading.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93dcfb",
   "metadata": {},
   "source": [
    "# Training Notebook (Colab-ready)\n",
    "\n",
    "This notebook contains environment setup (for Colab), repository fetch/checkout, dependency installation, and the training flow that imports from `src/`.\n",
    "It mirrors the modularized `00_setup.ipynb` steps but includes installation and runtime checks appropriate for a fresh Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73900468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Clone this repository into the Colab runtime if you haven't uploaded it.\n",
    "# If you already uploaded the repo or mounted Drive, skip this cell.\n",
    "import os\n",
    "if not os.path.exists('YouTube-Video-Summarization'):\n",
    "    import subprocess\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/shigenogoro/YouTube-Video-Summarization.git'])\n",
    "os.chdir('YouTube-Video-Summarization')\n",
    "print('Working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b01dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies. This will use the repo's requirements.txt and add common ML libs.\n",
    "# You can edit this to add GPU-specific packages (bitsandbytes, deepspeed) if needed.\n",
    "!pip install -r requirements.txt --quiet || true\n",
    "!pip install -q transformers datasets evaluate accelerate || true\n",
    "print('Dependencies installed (or already present).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic runtime checks (GPU, torch)\n",
    "import torch\n",
    "print('torch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        print('Device name:', torch.cuda.get_device_name(0))\n",
    "    except Exception as e:\n",
    "        print('Could not query device name:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config and small helpers\n",
    "from src.utils.io import load_yaml\n",
    "cfg_path = repo_root / 'configs' / 'model_bart_base.yaml'\n",
    "cfg = load_yaml(str(cfg_path))\n",
    "print('Loaded config keys:', list(cfg.keys()))\n",
    "MODEL_NAME = cfg['model']['model_name']\n",
    "DATA_CFG = cfg['data']\n",
    "PREPROCESS_CFG = cfg.get('preprocess', {})\n",
    "TRAINING_CFG = cfg.get('training_args', {})\n",
    "print('Model:', MODEL_NAME)\n",
    "print('Data config sample:', DATA_CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "from src.utils.seed import set_seed\n",
    "seed = TRAINING_CFG.get('seed', 42)\n",
    "set_seed(seed)\n",
    "print('Seed set to', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a17ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (try local/HF via existing loader, else fallback to small sample)\n",
    "from src.data.loaders import load_json_dataset\n",
    "from notebooks.helpers import sample_dataset\n",
    "\n",
    "try:\n",
    "    ds = load_json_dataset(DATA_CFG)\n",
    "    print('Dataset loaded with splits:', list(ds.keys()))\n",
    "except Exception as e:\n",
    "    print('Could not load dataset from disk/HF (falling back to sample):', e)\n",
    "    ds = {'train': sample_dataset(), 'validation': sample_dataset()}\n",
    "    print('Sample dataset created with columns:', ds['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model + tokenizer (downloads model weights on first run)\n",
    "from src.models.build_model import build_model_and_tokenizer\n",
    "print('Model name to load:', MODEL_NAME)\n",
    "model, tokenizer = build_model_and_tokenizer(MODEL_NAME, cfg.get('model', {}))\n",
    "print('Model and tokenizer ready — tokenizer vocab size =', getattr(tokenizer, 'vocab_size', 'n/a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize datasets using helpers.make_tokenize_fn and HF dataset.map (batched)\n",
    "from notebooks.helpers import make_tokenize_fn\n",
    "input_col = DATA_CFG.get('text_column', 'dialogue')\n",
    "summary_col = DATA_CFG.get('summary_column', 'summary')\n",
    "max_input = PREPROCESS_CFG.get('max_input_length', 1024)\n",
    "max_target = PREPROCESS_CFG.get('max_target_length', 256)\n",
    "tokenize_fn = make_tokenize_fn(tokenizer, input_col=input_col, target_col=summary_col, max_input_length=max_input, max_target_length=max_target)\n",
    "\n",
    "def maybe_map(split):\n",
    "    d = split\n",
    "    try:\n",
    "        tokenized = d.map(tokenize_fn, batched=True, remove_columns=d.column_names)\n",
    "        return tokenized\n",
    "    except Exception:\n",
    "        return d\n",
    "\n",
    "train_tok = maybe_map(ds['train'])\n",
    "eval_tok = maybe_map(ds.get('validation', ds.get('valid', ds.get('test', ds['train']))))\n",
    "print('Tokenization finished — sample keys for train tokenized:', list(train_tok.features.keys()) if hasattr(train_tok, 'features') else 'n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build trainer (does not start training yet)\n",
    "from src.training.trainer import build_trainer\n",
    "trainer = build_trainer(model, tokenizer, train_tok, eval_tok, cfg)\n",
    "print('Trainer built. Output dir =', trainer.args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca271cdc",
   "metadata": {},
   "source": [
    "## Start training\n",
    "The next cell will prompt you before starting training. Training in Colab may require GPU runtime and will download model weights and datasets. Be sure you have enough runtime quota and choose a GPU runtime (Runtime > Change runtime type > GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt before training to avoid accidental runs in Colab\n",
    "start = input('Start training now? (y/N): ')\n",
    "if start.strip().lower() == 'y':\n",
    "    print('Starting training...')\n",
    "    trainer.train()\n",
    "else:\n",
    "    print('Training skipped. To run, re-run this cell and enter y.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
